OK
OK
Query ID = sankuai_20171031200853_917b34c5-afb3-4509-b490-6e847dd4f30c
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1505297521386_3369, Tracking URL = http://gh-data-hdp-qa04.corp.sankuai.com:8088/proxy/application_1505297521386_3369/
Kill Command = /opt/meituan/hadoop-sentry-qa/bin/hadoop job  -kill job_1505297521386_3369
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Ended Job = job_1505297521386_3369
Stage-3 is selected by condition resolver.
Stage-2 is filtered out by condition resolver.
Stage-4 is filtered out by condition resolver.
Moving data to: viewfs://hadoop-meituan-test/user/hive/warehouse/encrypt_db4data.db/.hive-staging_hive_2017-10-31_20-08-53_378_4790862588643738501-1/-ext-10000
Loading data to table encrypt_db4data.table001
3 Rows loaded to encrypt_db4data.table001
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.15 sec   HDFS Read: 4121 HDFS Write: 49 SUCCESS
OK
OK
Query ID = sankuai_20171031200918_b1e00ca7-647b-4a70-bb5e-7cda9bbaa79e
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1505297521386_3370, Tracking URL = http://gh-data-hdp-qa04.corp.sankuai.com:8088/proxy/application_1505297521386_3370/
Kill Command = /opt/meituan/hadoop-sentry-qa/bin/hadoop job  -kill job_1505297521386_3370
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Ended Job = job_1505297521386_3370
Stage-3 is selected by condition resolver.
Stage-2 is filtered out by condition resolver.
Stage-4 is filtered out by condition resolver.
Moving data to: viewfs://hadoop-meituan-test/user/hive/warehouse/encrypt_db4data.db/.hive-staging_hive_2017-10-31_20-09-18_538_1749998967693220007-1/-ext-10000
Loading data to table encrypt_db4data.table_tgt
Moved: 'viewfs://hadoop-meituan-test/user/hive/warehouse/encrypt_db4data.db/table_tgt' to trash at: hdfs://hadoop-meituan-test/user/hdp_qa/.Trash/Current
1 Rows loaded to encrypt_db4data.table_tgt
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.94 sec   HDFS Read: 4216 HDFS Write: 17 SUCCESS
OK
name	ip
Query ID = sankuai_20171031200939_0832e830-5bce-43ca-8ffd-78eafea48f00
Total jobs = 1
Launching Job 1 out of 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1505297521386_3371, Tracking URL = http://gh-data-hdp-qa04.corp.sankuai.com:8088/proxy/application_1505297521386_3371/
Kill Command = /opt/meituan/hadoop-sentry-qa/bin/hadoop job  -kill job_1505297521386_3371
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Ended Job = job_1505297521386_3371
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.76 sec   HDFS Read: 6776 HDFS Write: 2 SUCCESS
OK
row_count
1
OK
table_tgt.name	table_tgt.ip
meituan	10.0.0.1
Query ID = sankuai_20171031201006_3284262d-c8c9-45a8-8f2f-2b5f2c091bfb
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1505297521386_3372, Tracking URL = http://gh-data-hdp-qa04.corp.sankuai.com:8088/proxy/application_1505297521386_3372/
Kill Command = /opt/meituan/hadoop-sentry-qa/bin/hadoop job  -kill job_1505297521386_3372
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Ended Job = job_1505297521386_3372
Stage-3 is selected by condition resolver.
Stage-2 is filtered out by condition resolver.
Stage-4 is filtered out by condition resolver.
Moving data to: viewfs://hadoop-meituan-test/user/hive/warehouse/encrypt_db4data.db/.hive-staging_hive_2017-10-31_20-10-06_996_6655565737138926264-1/-ext-10000
Loading data to table encrypt_db4data.table_tgt
Moved: 'viewfs://hadoop-meituan-test/user/hive/warehouse/encrypt_db4data.db/table_tgt' to trash at: hdfs://hadoop-meituan-test/user/hdp_qa/.Trash/Current
3 Rows loaded to encrypt_db4data.table_tgt
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.17 sec   HDFS Read: 3845 HDFS Write: 49 SUCCESS
OK
table001.name	table001.ip
Query ID = sankuai_20171031201028_684dc1b2-7b9c-497d-9220-0534df6b8e42
Total jobs = 1
Launching Job 1 out of 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1505297521386_3373, Tracking URL = http://gh-data-hdp-qa04.corp.sankuai.com:8088/proxy/application_1505297521386_3373/
Kill Command = /opt/meituan/hadoop-sentry-qa/bin/hadoop job  -kill job_1505297521386_3373
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Ended Job = job_1505297521386_3373
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.43 sec   HDFS Read: 6813 HDFS Write: 2 SUCCESS
OK
row_count
3
OK
table_tgt.name	table_tgt.ip
meituan	10.0.0.1
baidu	10.0.0.2
alibaba	10.0.0.3
Query ID = sankuai_20171031201053_48a77348-c18d-40e8-a043-0e74702d5cef
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1505297521386_3374, Tracking URL = http://gh-data-hdp-qa04.corp.sankuai.com:8088/proxy/application_1505297521386_3374/
Kill Command = /opt/meituan/hadoop-sentry-qa/bin/hadoop job  -kill job_1505297521386_3374
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Ended Job = job_1505297521386_3374
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.33 sec   HDFS Read: 8595 HDFS Write: 55 SUCCESS
OK
id	name	ip
1	alibaba	10.0.0.3
1	baidu	10.0.0.2
1	meituan	10.0.0.1
OK
OK
