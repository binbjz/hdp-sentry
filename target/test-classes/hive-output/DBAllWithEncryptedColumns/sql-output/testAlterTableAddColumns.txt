OK
OK
Query ID = sankuai_20171025124603_9365b108-0902-4779-bcae-58e324ee5813
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1505297521386_2468, Tracking URL = http://gh-data-hdp-qa04.corp.sankuai.com:8088/proxy/application_1505297521386_2468/
Kill Command = /opt/meituan/hadoop-sentry-qa/bin/hadoop job  -kill job_1505297521386_2468
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Ended Job = job_1505297521386_2468
Stage-3 is selected by condition resolver.
Stage-2 is filtered out by condition resolver.
Stage-4 is filtered out by condition resolver.
Moving data to: viewfs://hadoop-meituan-test/user/hive/warehouse/encrypt_db4alter.db/.hive-staging_hive_2017-10-25_12-46-03_817_6800702207351211854-1/-ext-10000
Loading data to table encrypt_db4alter.tbl4addcolumn
2 Rows loaded to encrypt_db4alter.tbl4addcolumn
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.75 sec   HDFS Read: 4876 HDFS Write: 12 SUCCESS
OK
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Unable to alter table. add columns failed, rollback failed. java.sql.SQLException: Connection is closed!
	at com.jolbox.bonecp.ConnectionHandle.checkClosed(ConnectionHandle.java:459)
	at com.jolbox.bonecp.ConnectionHandle.rollback(ConnectionHandle.java:1270)
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.updatePartitionsColumns(MetaStoreDirectSql.java:1790)
	at org.apache.hadoop.hive.metastore.ObjectStore.alterTableCascade(ObjectStore.java:2844)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:114)
	at com.sun.proxy.$Proxy7.alterTableCascade(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveAlterHandler.alterTable(HiveAlterHandler.java:141)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.alter_table_core(HiveMetaStore.java:3473)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.alter_table_with_cascade(HiveMetaStore.java:3441)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)
	at com.sun.proxy.$Proxy9.alter_table_with_cascade(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$MetricHMSProxy.invoke(HiveMetaStore.java:6049)
	at com.sun.proxy.$Proxy9.alter_table_with_cascade(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$alter_table_with_cascade.getResult(ThriftHiveMetastore.java:9480)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$alter_table_with_cascade.getResult(ThriftHiveMetastore.java:9464)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:732)
	at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:727)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1690)
	at org.apache.hadoop.hive.thrift.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:727)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
OK
ENCRYPTED_NAME_10573_encrypt_col1	tinyint             	ENCRYPTED_COMMENT_72112
ENCRYPTED_NAME_81779_encrypt_col2	bigint              	ENCRYPTED_COMMENT_77120
ENCRYPTED_NAME_69158_encrypt_col3	string              	ENCRYPTED_COMMENT_81491
FAILED: SemanticException [Error 10004]: Line 2:7 Invalid table alias or column reference 'id': (possible column names are: encrypted_name_29598_encrypt_col1, encrypted_name_12974_encrypt_col2, encrypted_name_54037_encrypt_col3) or Column insufficient privileges to access: id
FAILED: SemanticException [Error 10004]: Line 2:7 Invalid table alias or column reference 'encrypt_col1': (possible column names are: encrypted_name_57371_encrypt_col1, encrypted_name_87121_encrypt_col2, encrypted_name_88338_encrypt_col3) or Column insufficient privileges to access: encrypt_col1
FAILED: SemanticException Column insufficient privileges to access: <encrypt_db4alter>.<tbl4addcolumn>
OK
